{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import Evaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingEvaluator(Evaluator):\n",
    "    \"\"\"\n",
    "    The ranking evaluator provides the NDCG metric evaluting the predicted\n",
    "    ranking of category view count rather than the actual view counts.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=None):\n",
    "        self.k = k\n",
    "\n",
    "    def isLargerBetter(self):\n",
    "        return True\n",
    "\n",
    "    def _evaluate(self, predictedDF):\n",
    "        partition_window = Window.partitionBy('device_id')\n",
    "        windowSpec = partition_window.orderBy(F.col('prediction').desc())\n",
    "        per_user_predicted = predictedDF \\\n",
    "            .select('device_id', 'segment_id', 'prediction', F.rank().\n",
    "                    over(windowSpec).alias('rank')).where(\n",
    "                f'rank <= {self.k}').groupBy('device_id') \\\n",
    "            .agg(F.expr('collect_list(segment_id) as items'),\n",
    "                 F.count('segment_id').alias('num_items'))\n",
    "\n",
    "        per_user_predicted = per_user_predicted.filter(\n",
    "            F.col(\"num_items\") > 5).select(\"device_id\", \"items\")\n",
    "\n",
    "        windowSpec = partition_window.orderBy(F.col(\"frequency\").desc())\n",
    "        per_user_actual = predictedDF \\\n",
    "            .select('device_id', 'segment_id', \"frequency\", F.rank().\n",
    "                    over(windowSpec).alias('rank')) \\\n",
    "            .where(f'rank <= {self.k}').groupBy('device_id') \\\n",
    "            .agg(F.expr('collect_list(segment_id) as items'),\n",
    "                 F.count('segment_id').alias('num_items'))\n",
    "\n",
    "        per_user_actual = per_user_actual.filter(\n",
    "            F.col(\"num_items\") > 5).select(\"device_id\", \"items\")\n",
    "        perUserItemsRDD = per_user_predicted.join(\n",
    "            per_user_actual, 'device_id', 'inner').rdd.map(\n",
    "            lambda row: (row[1], row[2]))\n",
    "\n",
    "        if perUserItemsRDD.isEmpty():\n",
    "            return 0.0\n",
    "\n",
    "        rankingMetrics = RankingMetrics(perUserItemsRDD)\n",
    "        metric = rankingMetrics.ndcgAt(self.k)\n",
    "        return metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_device_ids(data):\n",
    "    \"\"\"\n",
    "    For Spark ALS implementation to work, the device and category IDs\n",
    "    have to be integers. Using the function monotonically_increasing_id\n",
    "    for this purpose.\n",
    "    \"\"\"\n",
    "    devices = data_ema.select('device_id').distinct()\n",
    "    devices = devices.repartition(1).withColumn(\n",
    "        \"device_id_int\", F.monotonically_increasing_id()).persist()\n",
    "    data = data_ema.join(devices, on=\"device_id\", how=\"left\")\n",
    "    return devices, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_als_model(training, test, ranks, reguls, iters,\n",
    "                    alphas, evaluator):\n",
    "    \"\"\"\n",
    "    Train the ALS collaborative filtering model with implicit ratings.\n",
    "    Parmeters\n",
    "    training: taining data set.\n",
    "    test: the validation data set.\n",
    "    ranks: the dimesnion for the low dimensional device product representation.\n",
    "    reguls: the  regularization to be applied.\n",
    "    alphas: the confidence estimates.\n",
    "    evaluator: the evaluator for the ALS model.\n",
    "\n",
    "    \"\"\"\n",
    "    als = ALS(userCol=\"device_id_int\", itemCol=\"segment_id\",\n",
    "              ratingCol=\"frequency\", coldStartStrategy=\"drop\",\n",
    "              implicitPrefs=True, nonnegative=False)\n",
    "\n",
    "    # We use a ParamGridBuilder to construct a grid of parameters to search\n",
    "    # over. TrainValidationSplit will try all combinations of values and\n",
    "    # determine best model using the evaluator.\n",
    "    paramGrid = ParamGridBuilder()\\\n",
    "        .addGrid(als.regParam, [0.1, 0.05]) \\\n",
    "        .addGrid(als.rank, [15])\\\n",
    "        .addGrid(als.alpha, [1.0])\\\n",
    "        .addGrid(als.maxIter, [15])\\\n",
    "        .build()\n",
    "\n",
    "    crossval = CrossValidator(estimator=als,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=evaluator,\n",
    "                              numFolds=3)  # use 3+ folds in practice\n",
    "\n",
    "    # Run cross-validation, and choose the best set of parameters.\n",
    "    model = crossval.fit(training)\n",
    "    finalModel = model.bestModel\n",
    "\n",
    "    predictions = finalModel.transform(test)\n",
    "\n",
    "    metric = evaluator.evaluate(predictions)\n",
    "    print(f\"NCDG \", metric)\n",
    "    best_alpha = model.bestModel._java_obj.parent().getAlpha()\n",
    "    best_regul = model.bestModel._java_obj.parent().getRegParam()\n",
    "    best_iter = model.bestModel._java_obj.parent().getMaxIter()\n",
    "    best_rank = model.bestModel._java_obj.parent().getRank()\n",
    "    print(f\"\"\"\n",
    "    best alpha: {best_alpha}\\nbest regul: {best_regul}\n",
    "    best iter: {best_iter}\\nbest rank: {best_rank}\n",
    "    \"\"\")\n",
    "    return finalModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalModel = train_als_model(\n",
    "    training, test, [15], [0.1, 0.15], [15], [1.0, 1.5], evaluator)\n",
    "\n",
    "print(\"Finished training the collaborative filtering model.\")\n",
    "\n",
    "reco = finalModel.recommendForAllItems(400000)\n",
    "reco = reco.withColumn(\"user_scores\", F.explode(reco.recommendations))\n",
    "reco = reco.withColumn('device_id_int', F.col('user_scores.device_id_int'))\n",
    "\n",
    "recommendations = reco.withColumn(\n",
    "    'rating', F.col('user_scores.rating')).drop(\n",
    "    F.col(\"recommendations\")).drop(F.col(\"user_scores\")).join(\n",
    "    categories.hint(\"broadcast\"), on=\"segment_id\", how=\"left\").join(\n",
    "    devices, on=\"device_id_int\", how=\"left\")\n",
    "\n",
    "recommendations = recommendations.filter(\n",
    "    F.col(\"rating\") >= 0.6).withColumnRenamed(\n",
    "    \"segment_id\", \"category_id\").select([\"device_id\", \"category_id\", \"rating\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
