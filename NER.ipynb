{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64512e37",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca77524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab369fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ner_dataset.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604ba8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1          NaN             of   IN      O\n",
       "2          NaN  demonstrators  NNS      O\n",
       "3          NaN           have  VBP      O\n",
       "4          NaN        marched  VBN      O\n",
       "5          NaN        through   IN      O\n",
       "6          NaN         London  NNP  B-geo\n",
       "7          NaN             to   TO      O\n",
       "8          NaN        protest   VB      O\n",
       "9          NaN            the   DT      O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d5341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb723221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdff13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_func(s):\n",
    "    return [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "grouped = df.groupby(\"Sentence #\").apply(agg_func)\n",
    "sentences = [s for s in grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dd89d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "sentences = sentences[:10000]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d67512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35178\n"
     ]
    }
   ],
   "source": [
    "#Lets find the number of words in the dataset\n",
    "words = list(set(df[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "print(n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fbf15",
   "metadata": {},
   "source": [
    "### Features for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12ef2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple feature map to feed arrays into the classifier. \n",
    "def feature_map(word):\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e89efdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6        London\n",
       "12         Iraq\n",
       "65         Hyde\n",
       "94      Britain\n",
       "106    Brighton\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Tag'] == 'B-geo', 'Word'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfae3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We divide the dataset into train and test sets\n",
    "words = [feature_map(w) for w in df[\"Word\"].values.tolist()]\n",
    "tags = df[\"Tag\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a17c5e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6edb3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),X=words, y=tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a708fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinav.sunderranjan/.pyenv/versions/3.7.12/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00       402\n",
      "       B-eve       0.00      0.00      0.00       308\n",
      "       B-geo       0.26      0.79      0.40     37644\n",
      "       B-gpe       0.25      0.06      0.09     15870\n",
      "       B-nat       0.00      0.00      0.00       201\n",
      "       B-org       0.65      0.17      0.27     20143\n",
      "       B-per       0.96      0.20      0.33     16990\n",
      "       B-tim       0.29      0.32      0.30     20333\n",
      "       I-art       0.00      0.00      0.00       297\n",
      "       I-eve       0.00      0.00      0.00       253\n",
      "       I-geo       0.00      0.00      0.00      7414\n",
      "       I-gpe       0.00      0.00      0.00       198\n",
      "       I-nat       0.00      0.00      0.00        51\n",
      "       I-org       0.36      0.03      0.06     16784\n",
      "       I-per       0.47      0.02      0.04     17251\n",
      "       I-tim       0.50      0.06      0.11      6528\n",
      "           O       0.97      0.98      0.97    887908\n",
      "\n",
      "    accuracy                           0.87   1048575\n",
      "   macro avg       0.28      0.15      0.15   1048575\n",
      "weighted avg       0.88      0.87      0.86   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_pred=pred, y_true=tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd9249",
   "metadata": {},
   "source": [
    "## NER using CRF\n",
    "The feature generation code is taken from the official crf suite https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fadd3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "import scipy.stats\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers,CRF\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b95acdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature set\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4a5f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "760c59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the train and test set\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "005fd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the CRF model\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09a062a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinav.sunderranjan/.pyenv/versions/3.7.12/lib/python3.7/site-packages/sklearn/base.py:213: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
      "  FutureWarning)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26b2b003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinav.sunderranjan/.pyenv/versions/3.7.12/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.12      0.01      0.02        76\n",
      "       B-eve       0.59      0.31      0.41        74\n",
      "       B-geo       0.82      0.88      0.85      7715\n",
      "       B-gpe       0.95      0.93      0.94      3257\n",
      "       B-nat       0.18      0.05      0.08        39\n",
      "       B-org       0.75      0.68      0.71      4329\n",
      "       B-per       0.81      0.77      0.79      3469\n",
      "       B-tim       0.91      0.85      0.88      4244\n",
      "       I-art       0.22      0.03      0.06        60\n",
      "       I-eve       0.45      0.14      0.22        63\n",
      "       I-geo       0.79      0.74      0.77      1502\n",
      "       I-gpe       0.79      0.38      0.51        29\n",
      "       I-nat       0.25      0.08      0.12        13\n",
      "       I-org       0.76      0.75      0.76      3524\n",
      "       I-per       0.83      0.88      0.85      3600\n",
      "       I-tim       0.82      0.71      0.76      1380\n",
      "           O       0.99      0.99      0.99    186878\n",
      "\n",
      "    accuracy                           0.97    220252\n",
      "   macro avg       0.65      0.54      0.57    220252\n",
      "weighted avg       0.96      0.97      0.96    220252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets evaluate the mode\n",
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f10c27b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'thousands',\n",
       "  'word[-3:]': 'nds',\n",
       "  'word[-2:]': 'ds',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  'BOS': True,\n",
       "  '+1:word.lower()': 'of',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-3:]': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'thousands',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'demonstrators',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'demonstrators',\n",
       "  'word[-3:]': 'ors',\n",
       "  'word[-2:]': 'rs',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'of',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'have',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VBP',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'have',\n",
       "  'word[-3:]': 'ave',\n",
       "  'word[-2:]': 've',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VBP',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'demonstrators',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'marched',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VBN',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'marched',\n",
       "  'word[-3:]': 'hed',\n",
       "  'word[-2:]': 'ed',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VBN',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'have',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VBP',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'through',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'through',\n",
       "  'word[-3:]': 'ugh',\n",
       "  'word[-2:]': 'gh',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'marched',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VBN',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'london',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'london',\n",
       "  'word[-3:]': 'don',\n",
       "  'word[-2:]': 'on',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'through',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'to',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'TO',\n",
       "  '+1:postag[:2]': 'TO'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'to',\n",
       "  'word[-3:]': 'to',\n",
       "  'word[-2:]': 'to',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'TO',\n",
       "  'postag[:2]': 'TO',\n",
       "  '-1:word.lower()': 'london',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNP',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'protest',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VB',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'protest',\n",
       "  'word[-3:]': 'est',\n",
       "  'word[-2:]': 'st',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VB',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'to',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'TO',\n",
       "  '-1:postag[:2]': 'TO',\n",
       "  '+1:word.lower()': 'the',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-3:]': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  '-1:word.lower()': 'protest',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VB',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'war',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'war',\n",
       "  'word[-3:]': 'war',\n",
       "  'word[-2:]': 'ar',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'the',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '+1:word.lower()': 'in',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'in',\n",
       "  'word[-3:]': 'in',\n",
       "  'word[-2:]': 'in',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'war',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'iraq',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'iraq',\n",
       "  'word[-3:]': 'raq',\n",
       "  'word[-2:]': 'aq',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'in',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'and',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'CC',\n",
       "  '+1:postag[:2]': 'CC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'and',\n",
       "  'word[-3:]': 'and',\n",
       "  'word[-2:]': 'nd',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'CC',\n",
       "  'postag[:2]': 'CC',\n",
       "  '-1:word.lower()': 'iraq',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNP',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'demand',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VB',\n",
       "  '+1:postag[:2]': 'VB'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'demand',\n",
       "  'word[-3:]': 'and',\n",
       "  'word[-2:]': 'nd',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VB',\n",
       "  'postag[:2]': 'VB',\n",
       "  '-1:word.lower()': 'and',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'CC',\n",
       "  '-1:postag[:2]': 'CC',\n",
       "  '+1:word.lower()': 'the',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'the',\n",
       "  'word[-3:]': 'the',\n",
       "  'word[-2:]': 'he',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  '-1:word.lower()': 'demand',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VB',\n",
       "  '-1:postag[:2]': 'VB',\n",
       "  '+1:word.lower()': 'withdrawal',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'withdrawal',\n",
       "  'word[-3:]': 'wal',\n",
       "  'word[-2:]': 'al',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'the',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '+1:word.lower()': 'of',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'of',\n",
       "  'word[-3:]': 'of',\n",
       "  'word[-2:]': 'of',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'withdrawal',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'british',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'JJ',\n",
       "  '+1:postag[:2]': 'JJ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'british',\n",
       "  'word[-3:]': 'ish',\n",
       "  'word[-2:]': 'sh',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'JJ',\n",
       "  'postag[:2]': 'JJ',\n",
       "  '-1:word.lower()': 'of',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'troops',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NNS',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'troops',\n",
       "  'word[-3:]': 'ops',\n",
       "  'word[-2:]': 'ps',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NNS',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'british',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'JJ',\n",
       "  '-1:postag[:2]': 'JJ',\n",
       "  '+1:word.lower()': 'from',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'IN',\n",
       "  '+1:postag[:2]': 'IN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'from',\n",
       "  'word[-3:]': 'rom',\n",
       "  'word[-2:]': 'om',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  '-1:word.lower()': 'troops',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NNS',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  '+1:word.lower()': 'that',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DT',\n",
       "  '+1:postag[:2]': 'DT'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'that',\n",
       "  'word[-3:]': 'hat',\n",
       "  'word[-2:]': 'at',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DT',\n",
       "  'postag[:2]': 'DT',\n",
       "  '-1:word.lower()': 'from',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '+1:word.lower()': 'country',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NN',\n",
       "  '+1:postag[:2]': 'NN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'country',\n",
       "  'word[-3:]': 'try',\n",
       "  'word[-2:]': 'ry',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NN',\n",
       "  'postag[:2]': 'NN',\n",
       "  '-1:word.lower()': 'that',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DT',\n",
       "  '-1:postag[:2]': 'DT',\n",
       "  '+1:word.lower()': '.',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': '.',\n",
       "  '+1:postag[:2]': '.'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': '.',\n",
       "  'word[-3:]': '.',\n",
       "  'word[-2:]': '.',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': '.',\n",
       "  'postag[:2]': '.',\n",
       "  '-1:word.lower()': 'country',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NN',\n",
       "  '-1:postag[:2]': 'NN',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed539ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
